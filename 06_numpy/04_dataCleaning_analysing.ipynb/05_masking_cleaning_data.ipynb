{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr=(np.array([-1,5,np.nan,9,-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Masking with boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False False]\n",
      "[nan]\n",
      "[-1.  5.  9. -2.]\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(arr))\n",
    "\n",
    "print(arr[np.isnan(arr)])\n",
    "print(arr[~np.isnan(arr)])\n",
    "arr=arr[~np.isnan(arr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Replacing outliers with specific value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  5.  5. -2.]\n",
      "[3. 5. 5. 3.]\n"
     ]
    }
   ],
   "source": [
    "arr[arr>5]=5\n",
    "print(arr)\n",
    "arr[arr<5]=3\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Removing the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n",
      "[3. 5. 5. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(arr))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Categorical data to one_hot_encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "--------------or--------------\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Categorical data\n",
    "categories = np.array(['Red', 'Blue', 'Green', 'Blue', 'Red'])\n",
    "\n",
    "# Get the unique categories\n",
    "unique_categories = np.unique(categories)\n",
    "\n",
    "# Create a dictionary that maps each category to a unique index\n",
    "category_to_index = {category: idx for idx, category in enumerate(unique_categories)}\n",
    "\n",
    "# Initialize a one-hot encoded matrix with zeros\n",
    "one_hot_encoded = np.zeros((categories.size, unique_categories.size))\n",
    "\n",
    "# Set the appropriate positions to 1\n",
    "for i, category in enumerate(categories):\n",
    "    one_hot_encoded[i, category_to_index[category]] = 1\n",
    "\n",
    "print(one_hot_encoded)\n",
    "\n",
    "\n",
    "#OR we can do this by eye also\n",
    "print(\"or\".center(30,'-'))\n",
    "one_hot_encoded_eye=np.eye(unique_categories.size)[range(unique_categories.size)]\n",
    "\n",
    "print(one_hot_encoded_eye)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 6 7 3 4 6 7 9]\n",
      "[-1.01015254 -0.10101525 -0.10101525 -1.01015254]\n",
      "[0.         0.14285714 0.57142857 0.71428571 0.14285714 0.28571429\n",
      " 0.57142857 0.71428571 1.        ]\n",
      "[0.22222222 0.33333333 0.66666667 0.77777778 0.33333333 0.44444444\n",
      " 0.66666667 0.77777778 1.        ]\n",
      "[ 1.    0.75 -0.   -0.25  0.75  0.5  -0.   -0.25 -0.75]\n"
     ]
    }
   ],
   "source": [
    "data=np.array([2,3,6,7,3,4,6,7,9])\n",
    "print(data)\n",
    "\n",
    "Mean=np.mean(data)\n",
    "std_dev=np.std(data)\n",
    "\n",
    "z_score=(arr-Mean)/std_dev\n",
    "print(z_score)\n",
    "\n",
    "min_max_scaling=(data-min(data))/(max(data)-min(data))\n",
    "print(min_max_scaling)\n",
    "\n",
    "max_absolute=data/max(np.abs(data))\n",
    "print(max_absolute)\n",
    "\n",
    "iqr=np.percentile(data,25)-np.percentile(data,75)\n",
    "robust_scaling=(data-np.median(data))/iqr\n",
    "print(robust_scaling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
